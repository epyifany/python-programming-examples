{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"chi_st.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"bhclIUNF6R5s","colab_type":"code","outputId":"a2195ed8-574b-423d-bdfe-116f7b4de6fd","executionInfo":{"status":"ok","timestamp":1552938326904,"user_tz":240,"elapsed":2008746,"user":{"displayName":"Yifan Yu","photoUrl":"https://lh4.googleusercontent.com/-Hk6Zmnm8kZo/AAAAAAAAAAI/AAAAAAAAAAs/YF2y3P5d6pk/s64/photo.jpg","userId":"18313827007117590150"}},"colab":{"base_uri":"https://localhost:8080/","height":238}},"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Created on Mon Jul  9 10:22:49 2018\n","\n","@author: mniemier\n","\"\"\"\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.layers import Activation, Dropout, Flatten, Dense\n","from keras.utils import plot_model\n","from keras import backend as K\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","###################################################################################################\n","# Define image size for network model -- all input images are scaled to this size.\n","###################################################################################################   \n","img_width, img_height = 150, 150\n","\n","###################################################################################################\n","# Include pointers to training and validation data folders -- be sure to examine subfolder structure\n","# --> I also define the # of training samples, validation samples, epochs, and batch size here.\n","###################################################################################################   \n","train_data_dir = '/content/gdrive/My Drive/Lab2/Images/chi_st/train'\n","validation_data_dir = '/content/gdrive/My Drive/Lab2/Images/chi_st/validation'\n","nb_train_samples = 5000\n","nb_validation_samples = 1000\n","epochs = 5\n","batch_size = 100\n","\n","###################################################################################################\n","# As before, this code simply organizes input data such that channels either come first or last\n","# depending on the backend used (TensorFlow or Theano)\n","###################################################################################################   \n","if K.image_data_format() == 'channels_first':\n","    input_shape = (3, img_width, img_height)\n","else:\n","    input_shape = (img_width, img_height, 3)\n","\n","###################################################################################################\n","# Define our CNN model\n","###################################################################################################\n","model = Sequential()\n","model.add(Conv2D(32, (5, 5), input_shape=input_shape))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(32, (5, 5)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Conv2D(32, (5, 5)))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","model.add(Flatten())\n","model.add(Dense(16))\n","model.add(Activation('relu'))\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","###################################################################################################\n","# To process images in respective directories, we can use the ImageDataGenerator class\n","#\tThe code provided here normalizes image data, etc.\n","#\tThe parameters will not be discussed further here, \n","#    but more information / options can be found at:  https://keras.io/preprocessing/image/ \n","###################################################################################################   \n","train_datagen = ImageDataGenerator(\n","    rescale=1. / 255,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True)\n","\n","###################################################################################################\n","# This is the augmentation configuration we will use for testing:  only rescaling\n","###################################################################################################\n","test_datagen = ImageDataGenerator(rescale=1. / 255)\n","\n","###################################################################################################\n","# Subsequent invocations of flow_from_directory() will use the paths to the training and validation \n","# data, and generate batches of data\n","# \n","# Note that if you wanted to work with grayscale images (for example) you could simply change \n","# color_mode to ‘gray_scale’ (and the number of color channels)\n","# \n","# Again, you will not need to change any parameters here, but a more detailed description of this \n","# class can also be found at the link above.\n","###################################################################################################\n","train_generator = train_datagen.flow_from_directory(\n","    train_data_dir,\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='binary')\n","\n","validation_generator = test_datagen.flow_from_directory(\n","    validation_data_dir,\n","    target_size=(img_width, img_height),\n","    batch_size=batch_size,\n","    class_mode='binary')\n","\n","###################################################################################################\n","# Finally, the invocation of model.fit_generator will simply train the model on batches of data.  \n","# More information can be found at:  https://keras.io/models/sequential/\n","# --> However, this is just analogous to model.fit() discussed in other examples.\n","###################################################################################################\n","model.fit_generator(\n","    train_generator,\n","    steps_per_epoch=nb_train_samples // batch_size,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    validation_steps=nb_validation_samples // batch_size)\n","\n","###################################################################################################\n","# Here, we save the model weights and generate an image of the network...\n","###################################################################################################\n","model.save('/content/gdrive/My Drive/Lab2/05_CNN_Chihuahua_StBernard/saved_model')\n","\n","#Does this line work with the to_file like that??\n","plot_model(model, to_file='/content/gdrive/My Drive/Lab2/05_CNN_Chihuahua_StBernard/model.png', show_shapes=True, show_layer_names=True)\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n","Found 300 images belonging to 2 classes.\n","Found 100 images belonging to 2 classes.\n","Epoch 1/5\n","50/50 [==============================] - 431s 9s/step - loss: 0.6937 - acc: 0.6096 - val_loss: 0.6439 - val_acc: 0.6300\n","Epoch 2/5\n","50/50 [==============================] - 408s 8s/step - loss: 0.4593 - acc: 0.7880 - val_loss: 0.5762 - val_acc: 0.7400\n","Epoch 3/5\n","50/50 [==============================] - 406s 8s/step - loss: 0.3674 - acc: 0.8502 - val_loss: 0.6400 - val_acc: 0.7100\n","Epoch 4/5\n","50/50 [==============================] - 406s 8s/step - loss: 0.2872 - acc: 0.8898 - val_loss: 0.7837 - val_acc: 0.7100\n","Epoch 5/5\n","50/50 [==============================] - 408s 8s/step - loss: 0.2546 - acc: 0.9090 - val_loss: 0.6311 - val_acc: 0.7500\n"],"name":"stdout"}]},{"metadata":{"id":"jYHeWMPE6YHj","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}